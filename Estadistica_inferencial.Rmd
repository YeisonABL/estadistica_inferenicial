---
title: "Estadística Inferencia"
output:
  html_document:
    df_print: paged
---
# Distribuciones de muestreo fundamentales y descripciones de datos. 

## Muestreo aleatorio


### Población y muestras

Definición: Una población consiste en la totalidad de las observaciones en las que estamos interesados

Definición: Una muestra es un subconjunto de una población

Definición:  Sean $X_{1},X_{2},...,X_{n}$ n variables independientes, cada una con una misma distribución de probabilidad $f(x)$. Definimos $X_{1},...,X_{n}$ con una muestra aleatoria de tamaño $n$ de la población $f(x)$ y escribimos su distribución de probabilidad conjunta como $$f(x_{1},...,x_{n})=f(x_{1})...f(x_{n})$$
 
## Algunos estadísticos importantes

Definición: Cualquier función de las variables aleatorias que forman una muestra aleatoria se llama estadístico 

### Tendencia central en la muestra. 

Definición: Si $X_{1},X_{2},...,X_{n}$ representan una muestra aleatoria de tamaño $n$, entonces **media de la muestra** se define mediante el estadístico
$$\bar{X}= \frac{1}{n}\sum_{i=1}^{n}X_{i}$$
Existen otros tipos de medias que se ajustan según la situación y la caracteristica de los datos u observaciones que se tienen. 
Una de estas variaciones es el ***media truncada***, la cual calcula el promedio dejando por fuera un número fijo de valores aleatorios en cada extremo y luego encontrando la media con los valores de las observaciones restantes.

Definición: si $X_{1},X_{2},...,X_{n}$ representa una muestra aleatoria de tamaño $n$, entonces la **media truncada** se define mediante el estadístico con $p$ valores más pequeños y más grandes omitidos es: 
 $$\bar{X}=\frac{\sum_{i=p+1}^{n-p}X_{i}}{n-2p}$$
La media es sensible a valores extremos, por lo tanto la media truncada elimina la influencia de valores extremos. 

Otro tipo de media es la **media ponderada**, que se calcula multiplicando cada observación o dato $X_{i}$ con un peso $w_{i}$ ya especificado y dividiendo esta suma por la suma de los pesos

Definición: Si $X_{1},X_{2},...,X_{n}$ representa una muestra aleatoria de tamaño $n$, entonces la **media ponderada** se define mediante el estadístico

$$\bar{X}_{w}= \frac{\sum_{i=1}^{n}w_{i}X_{i}}{\sum_{i=1}^{n}w_{i}}$$
Existen dos motivaciones por la cual utilizamos este tipo de promedio. 
1. Algunos valores son intrinsecamente mas variables que otros, y estos valores con alta variabilidad se le da un peso menos. Por ejemplo si estamos tomando el promedio de multiples sensonres y uno de estos sensores tiene poca presición, entonces podemos bajar su influencia utilizando los pesos para este sensor. 

2. Las observaciones o datos obtenimos no representan de manera equitativa diferentes grupos de los cuales queremos realizar mediciones. Por ejemplo debido a como un experimento en linea fue implementado fue realizado, no tenemos datos que reflejen de manera precisa todos los grupos que deseamos estudiar. Para corregir esto podemos dar pesos de mayor valor a los grupos con baja representación. 

Veamos el siguiente conjunto de datos. 

```{r}
library(readr)
state <- read_csv("data/state.csv")
head(state)
```
En la tabla observamos las primeras seis filas del conjunto de datos que contiene la población y tasas de homicidio. 


Encontremos la media de la población de los estados. 


```{r}
#mean es la función de r para encontrar el promedio o media. 
mean(state[['Population']])
```


```{r}
#Si deseamos encontrar la media truncada utilizamos el argumento trim
mean(state[['Population']], trim=0.1)
```
Este trim=0.1 elimina o deja de considerar el 10% de los datos en cada extremo

```{r}
#weighted.mean es la función de r para las medias ponderadas. 
weighted.mean(state[['Murder.Rate']], w=state[['Population']])
```


### Varianza de la muestra
La varianza debería indicar como se dispersan las observaciones a partir del promedio. Es posible tener dos conjuntos de observaciones con las mismas media o mediana, y que difieran de manera considerable en la variabilidad de sus mediciones alrededor del promedio. 

Considere las siguientes mediciones, en litros, para dos muestras de jugo de naranaja envasado por las compañias A y B

```{r}
#Creación de vectores con la información de cada muestra. 
Muestra_A <-c(0.97, 1.00, 0.94, 1.03, 1.06)
Muestra_B <-c(1.06, 1.01, 0.88, 0.91, 1.14)

#Creación de un dataframe. 
df<-data.frame(Muestra_A,Muestra_B)
df
```
Ahora, encontremos la media de cada una de las muestras.
```{r}
#Utilizamos la función cat para imprimir un mensaje frete a un resultado. 
cat("Media de la Muestra A: ", mean(Muestra_A))
```

```{r}
cat("Media de la Muestra B: ", mean(Muestra_B))
```
Vemos que ambas muestras tienen la misma media, $1.00$ litros. ¿Cómo podemos saber cual de las dos compañias envasa de manera mas uniforme? 
Buscamos en cual de las dos muestras la variabilidad o la dispersión de las observaciones respecto al promedio es menor. 

**Definición**: Si $X_{1},X_{2},...,X_{n} representan una muestra aleatoria de tamaño $n$, entonces la **varianza de la muestra** se define con el estadistico  
$$ S^{2} = \frac{1}{n-1}\sum_{i=1}^{n}\left(X_{i}-\bar{X}\right)^{2}$$
El valor calculado de $S^{2}$ para una muestra dada se denota con $s^2$.

```{r}
#Utilizamos la función sd para encontrar la desviación standar de la muestra. 
cat("Varianza de la Muestra A", (sd(Muestra_A))^2)
```

```{r}
cat("Varianza de la Muestra B",(sd(Muestra_B))^2)
```
Por lo tanto vemos que si compramos un jugo de naranja, tendríamos más confianza de que el envase seleccionado esté más cerca del promedio anunciado si lo compramos a la compañia A.

**Ejemplo:** Una comparación de los precios de café en cuatro tiendas de abarrotes, seleccionadas al azar, en San Diego mostró aumentos en comparación con el mes anterior de 12,15,17 y 20 centavos para una bolsa de 1 libra. Encuentre la varianza de esta muestra aleatoria de aunmento de precio. 
```{r}
Aumento_cafe <-c(12,15,17,20)
```


```{r}
Aumento_cafe_df <-data.frame(Aumento_cafe)
Aumento_cafe_df
```
Podemos utilizar la función sd(), que corresponde a la desviación estandar, y por definición el cuadrado de esta será el valor de la varianza. 
```{r}
#Podemos utilizar la función sd para encontrar la varianza elevando esta al cuadrado. 
(sd(Aumento_cafe))^2
```
```{r}
#Utilizamos var para encontrar la varianza de una muestra. 
var(Aumento_cafe)
```

Existe una expresión alternativa para la varianza y que es un teorema:
**Teorema:** Si $S^{2}$ es la varianza de una muestra aleatoria de tamaño $n$, podemos escribir:
$$S^{2}=\frac{1}{n(n-1)}\left[n\sum_{i=1}^{n}X_{i}^{2}- \left(\sum_{i=1}^{n}X_{i}\right)^{2}\right]$$
**Definición:** La **desviación estándar de la muestra, que se denota con $S$, es la raíz cuadrada positiva de la varianza de la muestra.

**Ejemplo:** Encuentre la varianza de los datos 3, 4, 5, 6, 6 y 7 que representan el número de truchas atrapadas por una muestra aleatoria de 6 pescadores el 19 de junio de 1996, en el lago Muskoka.
```{r}
pescador <- c(1, 2, 3, 4, 5, 6)
numero_truchas<-c(3, 4, 5, 6, 6, 7)
```


```{r}
numero_truchas_df<-data.frame(pescador, numero_truchas)
numero_truchas_df
```
Ahora, para encontrar la desviación estandar en R solo necesitamos utilizar la función sd()
```{r}
cat("La desviación estadar del numero de truchas es: ", sd(numero_truchas_df$numero_truchas) )
```



## Presentación de datos y métodos gráficos

### Gráfica de caja y extensión o gráfica de caja

La gráfica de caja se basa en los percentiles y da una visualización rapida a la distribución de los datos.

**Ejemplo:** Se midió el contenido de nicotina en una muestra aleatoria de 40 cigarrillos. Los datos se ven en la siguiente tabla.
```{r}
nicotina <-c(1.09, 0.85, 1.86, 1.82, 1.40, 1.92, 1.24, 1.90, 1.79, 1.64, 2.31, 1.58, 1.68, 2.46, 2.09, 1.79, 2.03, 1.51, 1.88, 1.75, 2.28, 1.70, 1.64, 2.08, 1.63, 1.74, 2.17, 0.72, 1.67, 2.37, 1.47, 2.55, 1.69, 1.37, 1.75, 1.97, 2.11, 1.85, 1.93, 1.63)
```

```{r}
nicotina_df<-c(nicotina)
nicotina
```

```{r}
#boxplot es la función para crear graficos de cajas y bigotes. 
boxplot(nicotina_df)
```

De esta grafica podemos observar que la media de la cantidad de nicotina es alrededor de $1.7$ y los datos $0.72$ y $0.85$ como valores extremos inferiores; en tanto que la observación $2.55$ es un valor extremo moderado superior. En este ejemplo el raangi intercuartil es $0.365$, y $1.5$ veces el rango intercuartil es $0.5475$

Veamos cual es la media de estos datos. 

```{r}
mean(nicotina_df)
```
la parte superior y la parte inferior de la caja son el percentil del $75$ y $25$. La mediana es la linea horizontal que esta dentro de la caja. Las lineas discontinuas, tambien llamadas como bigotes se extienden desde la parte superior e inferior del cuadro para indicar el rango de la mayor parte de los datos. Por defecto, la función de $R$ extiende los bigotes al punto más allá de la caj, execepto que no ira mas allá de $1.5$ veces el rango intercuartil.

### Gráfica de cuantiles. 

El propósito de las gráficas de cuantiles consiste en describir, en forma de muestra, la función de distribución acumulada. 

**Definición** Un cuantil de una muestra, $q(f)$, es un valor para el que una fracción específica $f$ de los valores de los datos es menor que o igual a $q(f)$

Una gráfica de cuantiles simplemente *gráfica los valores de los datos en el eje vertical contra una evaluación empírica de la fracción de observaciones excedidad por los valores de los datos*



### Detección de desviaciones de la normalidad.


##Gráfica de cuantiles-cuantiles normales. 

La metodología incluye una gráfica de los cuantiles empíricos recién presentados contra el cuantil correspondiente de la distribución normal

**Definición** La **gráfica de cuantiles-cuantiles normales* es una grafica de $y_{(i)}$ observaciones ordenadas contra $q_{0,1}(f_{i})$, donde $f_{i}=\frac{i-\fra{3}{8}}{n+\frac{1}{4}}$

Una relación cercana a una línea recta sugiere que los datos provienen de una distribución normal. La intersección en el eje vertical es una estimación de la media de la población $\mu$ y la pendiente es una estimación de la desviación estándar $\sigma$. 
**Ejemplo**
```{r}
#repeticiones del experimento
rep = 100
#tamano de la muestra
n = 16
#media de la población
mu = 800
#desviacion estandar de la población 
sigma = 40
#matriz para guardar las muestras
muestras = matrix(data = NA, nrow = rep, ncol = n)
#Generacion de las muestras de tamaño n provenientes de una población
#Normal con media mu y desviación sigma
for (i in 1:rep) {
  muestras[i,] = rnorm(n, mean=mu, sd=sigma) 
}
#Convertir la matriz muestras en un data.frame
muestras = data.frame(muestras)
head(muestras)
```
```{r}
qqnorm(muestras$X1, pch = 1, frame = FALSE)
qqline(muestras$X1, col = "steelblue", lwd = 2)
```

### Graficación de la probabilidad normal.. 

```{r}
Estación_1 <-c(5.30, 4.980, 13.700, 11.910, 10.730, 8.130, 11.400, 26.850, 860, 17.660, 2.200, 22.800, 4.250, 1.130, 15.040, 1.690)

Estación_2 <-c(2.800, 4.670, 6.890, 7.720, 7.030, 7.330, 2.810, 1.330, 3.320, 1.230, 2.130, 2.190, NA, NA, NA, NA)
```


```{r}
Número_de_organismos_m2 <-data.frame(Estación_1, Estación_2)
Número_de_organismos_m2
```

## Distribuciones muestrales de medias

El campo de la inferencia estadística se trata básicamente con generalizaciónes y predicciones.

### Inferencias sobre la población a patir de la información de la muestra. 

**Definición** La distribuciòn de probabilidad de in estadìstico se llama **distribuciòn muestral.**

## Distribuciones muestrales de medias


**Teorema del lìmite central: ** si $\bar{X}$ es la media de de una muestra aleatoria de tamaño $n$ tomada de una población con media $\mu$ y varianza finita $\sigma^{2}$, entonces la forma límite de la distribución de $$Z = \frac{\bar{X}-\mu}{\frac{\sigma}{\sqrt{n}}}$$
conforme $n \rightarrow \infty$, es la distribución normal estándar $n(z;0,1)$


**Ejemplo** Una empresa de material eléctrico fabrica bombillas de luz que tienen una duración que se distribuye aproximadamente en forma normal, con media de 800 horas y desviación estándar de 40 horas. Encuentre la probabilidad  de que una muestra aleatoria de 16 bombillas tengan una vida promedio de menos de 775 horas. 

```{r}
#repeticiones del experimento
rep = 10000
#tamano de la muestra
n = 16
#media de la población de bombillos
mu = 800
#desviacion estandar de la población de bombillos
sigma = 40
#matriz para guardar las muestras
muestras = matrix(data = NA, nrow = rep, ncol = n)
#Generacion de las muestras de tamaño n provenientes de una población
#Normal con media mu y desviación sigma
for (i in 1:rep) {
  muestras[i,] = rnorm(n, mean=mu, sd=sigma) 
}
#Convertir la matriz muestras en un data.frame
muestras = data.frame(muestras)
#Crear una variable columna al final del data.frame con la proporcion de exitos
#llamada Media
head(muestras)
```


```{r}
muestras$Media = apply(muestras, 1, mean)
#Histograma de frecuencias para la variable aleatorio o estimador Media
hist(muestras$Media, breaks=50)
#Media del estimador Media
mean(muestras$Media)
#Varianza del estimador Media
var(muestras$Media)
#Desviacion estandar del estimador Media
sd(muestras$Media)

#Histograma con frecuencias relativas
hist(muestras$Media, breaks=50, freq = FALSE)
#Curva normal teorica superpuesta
curve(dnorm(x, mean=mu, sd=sigma/sqrt(n)), col="red", lwd=2, add=TRUE, yaxt="n")

# Encuentre la probabilidad de que una muestra aleatoria 
# de 16 bombillas tenga una vida promedio de menos de 
# 775 horas.
```

```{r}
#Indicadora de que Medias son menores que 775
muestras$ind = (muestras$Media < 775)
#Conteo del numero de Medias menores a 775
sum(muestras$ind)
#Proporcion del numero de Medias menores a 775
sum(muestras$ind)/rep
```

## Inferencias sobre la media de la población

**Ejemplo:** Un importante proceso de fabricación produce partes de componentes cilíndricos para la industria automotriz. Es importante que el proceso produzca partes que tengan una media de 5 milímetros. El ingeniero implicado hace la conjetura de que la media de la población es de 5.0 milímetros. Se lleva a cabo un experimento donde se seleccionan al azar 100 partes elaboradas por el proceso y se mide el diámetro de cada una de ellas. Se sabe que la desviación estándar de la población es $\sigma=0.1$. El experimento indica un diámetro promedio de la muestra $\bar{x}=5.027$ milímetros. ¿Esta información de la muestra parece apoyar o refutar la conjetura del ingeniero?

```{r}
#repeticiones del experimento
rep_2 = 10000
#tamano de la muestra
n_2 = 100
#media del diametro de las piezas
mu_2 = 5
#desviacion estandar del diametro de las piezas
sigma_2 = 0.1
#matriz para guardar las muestras
muestras_2 = matrix(data = NA, nrow = rep_2, ncol = n_2)
#Generacion de las muestras de tamaño n provenientes de una población
#Normal con media mu y desviación sigma
for (i in 1:rep) {
  muestras_2[i,] = rnorm(n_2, mean=mu_2, sd=sigma_2) 
}
#Convertir la matriz muestras en un data.frame
muestras_2 = data.frame(muestras_2)
head(muestras_2)


```


```{r}
#Crear una variable columna al final del data.frame con la proporcion de exitos
#llamada Media
muestras_2$Media = apply(muestras_2, 1, mean)
#Histograma de frecuencias para la variable aleatorio o estimador Media
hist(muestras_2$Media, breaks=50)
#Media del estimador Media
mean(muestras_2$Media)
#Varianza del estimador Media
var(muestras_2$Media)
#Desviacion estandar del estimador Media
sd(muestras_2$Media)

#Histograma con frecuencias relativas
hist(muestras_2$Media, breaks=50, freq = FALSE)
#Curva normal teorica superpuesta
curve(dnorm(x, mean=mu_2, sd=sigma_2/sqrt(n_2)), col="red", lwd=2, add=TRUE, yaxt="n")

# El ingeniero implicado hace la conjetura de que la media 
#de la población es de 5.0 milímetros. 
# Se lleva a cabo un experimento donde se seleccionan al 
#azar 100 partes elaboradas por el proceso y se mide el 
# diámetro de cada una de ellas.
# El experimento indica un diámetro promedio de la muestra
# x_barra = 5.027 milímetros. ¿Esta información de la 
#muestra parece apoyar o refutar la conjetura del ingeniero?

#Indicadora de que Medias mayores que 5.027
muestras_2$ind = (muestras_2$Media > 5.027)
#Conteo del numero de Medias mayores a 5.027
sum(muestras_2$ind)
#Proporcion del numero de Medias mayores a 5.027
2*sum(muestras_2$ind)/rep
```
### Distribución muestral de la diferencia entre dos promedios. 

**Teorema:** Si se extraen al azar muestras independientes de tamaños $n_1$ y $n_2$ de dos poblaciones, discretas o continuas, con medias $\mu_1$ y $\mu_2$ y varianzas $\sigma_{1}^{2}$ y $\sigma_{2}^{2}$ respectivamente, entonces la distribución muestras de las medias, $\bar{X_{1}}-\bar{X}_{2}$, está distribuida aproximadamente de forma normal con media y varianza dadas por $$\mu_{\bar{X_1}-\bar{X_2}}=\mu_{1}-\mu_{2}$$ y $$\sigma_{\bar{X_1}-\bar{X_2}}^{2}=\frac{\sigma_{1}^{2}}{n_1}+\frac{\sigma_{2}^{2}}{n_2}$$ De aquí,
$$Z=\frac{(\bar{X_1}-\bar{X_2})-(\mu_1-\mu_2)}{\sqrt{(\sigma_{1}^{2}/n_1)+(\sigma_{2}^{2}/n_2)}}$$
Es aproximadamente una variable normal estándar. 

**Ejemplo:** Se llevan a cabo dos experimentos independientes en los que se comparan dos tipos diferentes de pintura. Se pintan 18 especímenes con el tipo A y en cada uno se registra el tiempo de secado en horas. Lo mismo se hace con el tipo B. Se sabe que las desviaciones estándar de la población son ambas $1.0$. 
Suponiendo que el tiempo medio de secado es igual para los dos tipos de pintura, encuentre $P(\bar{X_A}-\bar{X_b}>1.0)$, donde $\bar{X_A}$ y $X_{X_B}$, son los tiempos promedio de secado para muestras de tamaño $n_A=n_B=18$

```{r}
#repeticiones del experimento
rep = 10000
#tamano de la muestra
n_1 = 30
n_2 = 30
#media del diametro de las piezas
mu_1 = 5
mu_2 = 5
#desviacion estandar del diametro de las piezas
sigma_1 = 0.1
sigma_2 = 0.1
#matriz para guardar las muestras
muestras_1 = matrix(data = NA, nrow = rep, ncol = n_1)
muestras_2 = matrix(data = NA, nrow = rep, ncol = n_2)
#Generacion de las muestras de tamaño n provenientes de una población
#Normal con media mu y desviación sigma
for (i in 1:rep) {
  muestras_1[i,] = rnorm(n_1, mean=mu_1, sd=sigma_1) 
}

for (i in 1:rep) {
  muestras_2[i,] = rnorm(n_2, mean=mu_2, sd=sigma_2) 
}
#Convertir la matriz muestras en un data.frame
muestras_1 = data.frame(muestras_1)
muestras_2 = data.frame(muestras_2)

muestras_1$Media = apply(muestras_1, 1, mean)
muestras_2$Media = apply(muestras_2, 1, mean)


head(muestras_1)
head(muestras_2)

```




```{r}
muestras_df = muestras_1-muestras_2
muestras_df
```
```{r}


#Histograma de frecuencias para la variable aleatorio o estimador Media
hist(muestras_df$Media, breaks=50)
#Media del estimador Media
mean(muestras_df$Media)
#Varianza del estimador Media
var(muestras_df$Media)
#Desviacion estandar del estimador Media
sd(muestras_df$Media)

```
```{r}
#Histograma con frecuencias relativas
hist(muestras_2$Media, breaks=50, freq = FALSE)
#Curva normal teorica superpuesta
curve(dnorm(x, mean=mu_2, sd=sigma_2/sqrt(n_2)), col="red", lwd=2, add=TRUE, yaxt="n")

# El ingeniero implicado hace la conjetura de que la media 
#de la población es de 5.0 milímetros. 
# Se lleva a cabo un experimento donde se seleccionan al 
#azar 100 partes elaboradas por el proceso y se mide el 
# diámetro de cada una de ellas.
# El experimento indica un diámetro promedio de la muestra
# x_barra = 5.027 milímetros. ¿Esta información de la 
#muestra parece apoyar o refutar la conjetura del ingeniero?

#Indicadora de que Medias mayores que 5.027
muestras_2$ind = (muestras_2$Media > 5.027)
#Conteo del numero de Medias mayores a 5.027
sum(muestras_2$ind)
#Proporcion del numero de Medias mayores a 5.027
2*sum(muestras_2$ind)/rep
```








## Distribución muestral de $S^2$

**Teorema**  si $S^2$ es la varianza de una muestra aleatoria de tamaño $n$ que se toma de una población normal que tiene la varianza $\sigma^{2}$, entonces el estadistico $$X^{2} =\frac{(n-1)S^{2}}{\sigma^{2}}=\sum_{i=1}^{n}\frac{(X_{i}-\bar{X})^2}{\sigma^2}$$
tiene una distribución chi cuadrara con $v=n-1$ grados de libertad


**Ejemplo**Un fabricante de baterías para automóvil garantiza que sus baterías durarán, en promedio, 3 años con una desviación estándar de 1 año. Si cinco de estas baterías tienen duraciones de 1.9, 2.4, 3.0, 3.5 y 4.2 años,¿el fabricante aún está convencido de que sus baterías tienen una desviación estándar de 1 año? Suponga que la duración de la batería sigue una distribución normal.


```{r}

#repeticiones del experimento
rep = 10000
#tamano de la muestra
n = 5
#media del diametro de las piezas
mu = 3
#desviacion estandar del diametro de las piezas
sigma = 1
#matriz para guardar las muestras
muestras = matrix(data = NA, nrow = rep, ncol = n)
#Generacion de las muestras de tamaño n provenientes de una población
#Normal con media mu y desviación sigma
for (i in 1:rep) {
  muestras[i,] = rnorm(n, mean=mu, sd=sigma) 
}
#Convertir la matriz muestras en un data.frame
muestras = data.frame(muestras)
#Crear una variable columna al final del data.frame con la proporcion de exitos
#llamada Media
muestras$S_2 = apply(muestras, 1, var)
#Crear una variable transformando S_2 que se llame Chi_Sq
muestras$Chi_Sq = (n-1)*muestras$S_2/sigma^2
#Histograma de frecuencias para la variable aleatoria o estimador Varianza
hist(muestras$S_2, breaks=50)
#Media del estimador Varianza
mean(muestras$S_2)
#Varianza del estimador Varianza
var(muestras$S_2)
#Histograma de frecuencias para la variable aleatorio o estimador Chi_Sq
hist(muestras$Chi_Sq, breaks=50)
#Media del estimador Chi_Sq
mean(muestras$Chi_Sq)
#Varianza del estimador Chi_Sq
var(muestras$Chi_Sq)

#Histograma con frecuencias relativas
hist(muestras$Chi_Sq, breaks=50, freq = FALSE)
#Curva Chi-cuadrado teorica superpuesta
curve(dchisq(x, df=4), col="red", lwd=2, add=TRUE, yaxt="n")

## -- Solución del ejercicio

#Creacion del vector de datos
datos = c(1.9, 2.4, 3.0, 3.5, 4.2)
#Calculo de su varianza
s2 = var(datos)
#Transformacion Chi-cuadrado
chis_quad = (n-1)*s2/sigma^2

#Que porcentaje de repeticiones del experimento son menores que 
#el valor de chis_quad
sum(muestras$Chi_Sq<chis_quad) 
#Que porcentaje de repeticiones del experimento son mayores que 
#el valor de chis_quad
sum(muestras$Chi_Sq>chis_quad)

#Podríamos preguntarnos entre que par de valores "centrales"
#se concentra el 95% de los valores de la variable Chi_Sq
quantile(muestras$Chi_Sq,c(0.025,0.975))

#Como el valor de chis_quad es un valor que cae entre estos
#dos valores, el valor de la muestra tiene alta probbilidad
#que ocurra
```

## Distribución t
**Teorema** Sea $Z$ una variable aleatoria normal estándar y $V$ una variable aleatoria chi cuadrada con $v$ grados de libertad. Si $Z$ y $V$ son independientes, entonces, la distribución de la variable aleatoria $T$, donde
$$T = \frac{Z}{\sqrt{V/v}}$$
está dada por la función de densidad
$$h(t)=\frac{\Gamma[(v+1)/2]}{\Gamma(v/2)\sqrt{\pi v}}\left(1+\frac{t^2}{v}\right)^{-(v+1)/2}$$
**Ejemplo** El valor $t$ con $v=14$ grados de libertad que deja un área de $0.025$ a la izquierda y, por lo tanto. un área de $0.975$ a la derecha

```{r}
-qt(0.025,14)
```
```{r}
qt(0.975, 14)
```

**Ejemplo**
Encuentre $P\letf(-t_{0.025}< T < t_{0.05}\right)

```{r}
qt(0.05,df=1)
```


Ésta se conoce como la distribución t con $v$ grados de libertad.
**Ejemplo** Un ingeniero químico afirma que el rendimiento medio de la población de cierto proceso de lotes es de 500 gramos por milímetro de materia prima. Para verificar dicha afirmación muestrea 25 lotes cada mes. Si el valor $t$ calculado cae entre $-t_{0.05}$ y $t_{0.05}$, queda satisfecho con su afirmación. ¿Qué conclusión debería obtener de una muestra que tiene media $\bar{x}=518$ gramos por milímetro y una desviación  estándar muestra de $s=40$? Suponga que la distribución de rendimientos es aproximadamente normal. 

```{r}
n <- 25
df <- n - 1
samples <- rt(n, df)
hist(samples, breaks = 'Scott', freq = FALSE)
samples
```
```{r}
x <- seq(-2, 4, by = 1)
dt(x, df = n-1)
```

```{r}
pt(-0.05, df) + pt(0.05, df,lower.tail = FALSE)
```

```{r}
qt(0.05,df)
```
```{r}
qt(1-0.05,df)
```
```{r}
pt(2.25,24, lower.tail = FALSE)
```



```{r}
x<-seq(-4,4, by=1)
dt(x, df=25)
```


## Distribución F



Suponga que las muestras aleatorias de tamaño $n_1$ y $n_2$ se seleccionan de dos poblaciones normales con varianzas $\sigma_{1}^{2}$ y $\sigma_{2}^{2}$ respectivamente. Sabemos que 

$$X_{1}^{2} = \frac{(n_1-1)S_{1}^{2}}{\sigma_{1}^{2}} \hspace{1cm}X_{1}^{2} = \frac{(n_2-1)S_{2}^{2}}{\sigma_{2}^{2}}$$
son variables aleatorias que tienen distribuciones chi cuadradas con $v_1=n_1 -1$ y $v_2 = n_2-1$ grados de libertad. Además, como las muestras se seleccionan al azar, la tratamos con variables aleatorias independientes y, entonces, usando el teorema anterior

**Teorema** Si $S_{1}^{2}$ y $S_{1}^{2}$ son las varianzas muestras aleatorias independientes de tamaño $n_1$ y $n_2$ tomadas de poblaciones normales con varianzas $\sigma_{1}^{2}$ $\sigma_{2}^{2}$, respectivamente, entonces, 
$$F=\frac{S_{1}^{2}/\sigma_{1}^{2}}{S_{2}^{2}/\sigma_{2}^{2}}= \frac{\sigma_{2}^{2}S_{1}^{2}}{\sigma_{1}^{2}S_{2}^{2}} $$



### ¿Para qué se utiliza la distribución F?

La distribución $F$ se usa en situaciones de dos muesrtas para realizar inferencias acerca de las varianzas de población. La distribución $F$ se aplica a muchos otros tipos de problemas en los cuales están relacionadas las varianzas muestrales. De hecho la distribución $F$ se llama *distribución de razón de varianzas*

```{r}
pintura <-c('A', 'B', 'C')
media_muestral <-c(4.5, 5.5, 6.5)
varianza_muestral <-c(0.20, 0.14, 0.11)
tamaño_muestral <- c(10, 10, 10)
tiempo_secado <-data.frame(pintura, media_muestral, varianza_muestral, tamaño_muestral)
tiempo_secado
```
El problema se centra alrededor de si los promedios muestrales están los suficientemente alejados o no. La implicación "suficientemente alejados" resulta muy importante. Parecería razonable que si la variabilidad entre los promdios muestrales es mayor que lo que se esperaría por casualidad, los datos no apoyan la conclusión de $\mu_A=\mu_B=\mu_C$. 

```{r}
curve(df(x, df1 = 10, df2 = 20), from = 0, to = 4)
```

```{r}
df(1.2, df1=10, df2=20)
```

```{r}

```



